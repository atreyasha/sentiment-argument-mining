

@online{subjective,
  author = {TU Darmstadt},
  title = {Subjective Verbs Lexicons},
  url = {https://www.informatik.tu-darmstadt.de/ukp/research_6/data/sentiment_analysis/subjective_verbs_lexicons/index.en.jsp}
}

@misc{schnfeld2019security,
    title={The UN Security Council debates 1995-2017},
    author={Mirco Sch√∂nfeld and Steffen Eckhard and Ronny Patz and Hilde van Meegdenburg},
    year={2019},
    eprint={1906.10969},
    archivePrefix={arXiv},
    primaryClass={cs.DL}
}

@misc{potash2016heres,
    title={Here's My Point: Joint Pointer Architecture for Argument Mining},
    author={Peter Potash and Alexey Romanov and Anna Rumshisky},
    year={2016},
    eprint={1612.08994},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@inproceedings{haddadan-etal-2019-yes,
    title = "Yes, we can! Mining Arguments in 50 Years of {US} Presidential Campaign Debates",
    author = "Haddadan, Shohreh  and
      Cabrio, Elena  and
      Villata, Serena",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P19-1463",
    doi = "10.18653/v1/P19-1463",
    pages = "4684--4690",
    abstract = "Political debates offer a rare opportunity for citizens to compare the candidates{'} positions on the most controversial topics of the campaign. Thus they represent a natural application scenario for Argument Mining. As existing research lacks solid empirical investigation of the typology of argument components in political debates, we fill this gap by proposing an Argument Mining approach to political debates. We address this task in an empirical manner by annotating 39 political debates from the last 50 years of US presidential campaigns, creating a new corpus of 29k argument components, labeled as premises and claims. We then propose two tasks: (1) identifying the argumentative components in such debates, and (2) classifying them as premises and claims. We show that feature-rich SVM learners and Neural Network architectures outperform standard baselines in Argument Mining over such complex data. We release the new corpus USElecDeb60To16 and the accompanying software under free licenses to the research community.",
}

@inproceedings{ontology,
author = {Groza, Adrian and Popa, Oana},
year = {2016},
month = {09},
pages = {77-84},
title = {Mining arguments from cancer documents using Natural Language Processing and ontologies},
doi = {10.1109/ICCP.2016.7737126}
}

@inproceedings{mpqa,
author = {Wilson, Theresa and Wiebe, Janyce and Hoffmann, Paul},
year = {2005},
month = {10},
pages = {},
title = {Recognizing Contextual Polarity in Phrase-Level Sentiment Analysis},
journal = {Proceedings of HLT/EMNLP},
doi = {10.3115/1220575.1220619}
}

@inproceedings{vader,
author = {Hutto, C.J. and Gilbert, Eric},
year = {2015},
month = {01},
pages = {},
title = {VADER: A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text},
journal = {Proceedings of the 8th International Conference on Weblogs and Social Media, ICWSM 2014}
}

@inproceedings{peldszus2015annotated,
  title={An annotated corpus of argumentative microtexts},
  author={Peldszus, Andreas and Stede, Manfred},
  booktitle={Argumentation and Reasoned Action: Proceedings of the 1st European Conference on Argumentation, Lisbon},
  volume={2},
  pages={801--816},
  year={2015}
}

@article{stab2017parsing,
  title={Parsing argumentation structures in persuasive essays},
  author={Stab, Christian and Gurevych, Iryna},
  journal={Computational Linguistics},
  volume={43},
  number={3},
  pages={619--659},
  year={2017},
  publisher={MIT Press}
}

@misc{devlin2018bert,
    title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
    author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
    year={2018},
    eprint={1810.04805},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{lan2019albert,
    title={ALBERT: A Lite BERT for Self-supervised Learning of Language Representations},
    author={Zhenzhong Lan and Mingda Chen and Sebastian Goodman and Kevin Gimpel and Piyush Sharma and Radu Soricut},
    year={2019},
    eprint={1909.11942},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}