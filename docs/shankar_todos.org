** Developments

*** Argumentation workflow

**** Sequence encoding
***** TODO add data options with both cased and non-cased views 
***** TODO redefine padding length based on UNSC dataset paragraph or processing lengths
***** TODO consider allowing for vocabulary pruning and flexible padding
***** need to split UNSC smaller speech segments or paragraphs to pass into pipeline
***** simple (task 1) -> 1: claim, 2: premise, 3: non-argument
***** tree (task 1) -> 1: claim, 2: aux claim connecting to same claim (behind), 3: premise connecting to claim, 4: aux premise connecting to same premise (behind), 5: non-argument
***** tree (task 2) -> distances to connective argument components which can help form tree

**** Domain debiasing
***** TODO remove capital names and references to reduce bias
***** TODO consider using special word embeddings and keep unmodified to retain word relationships
***** TODO re-sampling procedure to re-train inputs with rare words more than common words
***** TODO possibly add unknown token types eg. pos-tags, ner taggers, verb types, etc.
***** experiment specific entity/token masking to prevent domain-specific bias from training vocabulary
***** perhaps collapse all first, second and third-person pronouns to prevent self-referential bias 
***** add different classes in unknown vocabulary -> such as unknown noun, unknown adjective etc.

**** Architecture
***** TODO port transformer code to pytorch and attempt running on colab
***** TODO perform single task first, and then multi task to check performance
***** consider non-transformer approach for character data due to GPU OOM issues -> perhaps adding more features to unknown words
***** try novel architectures for seq2seq task, egs. GRU, transformer, BERT pre-trained models
***** think of best unique tree structure classification, perhaps with argument connection distances
***** if working with three-way task, need to think of how to pass a gradient on non-existent examples -> perhaps some kind of negative sampling procedure

**** Local development
***** TODO figure out pip local environment for earlier tensorflow version
***** TODO find out how to include fixed names into requirements.txt file such as tensorflow, despite no explicit call in script

**** Ideas to extrapolate
***** OOM issues for character-transformer model
***** ibm argumentation dataset
***** coreference resolution for tree structures
***** try genereous claims and premises creation and map via negative sampling to actual trees and redundant candidates

**** Documentation
***** redo colab notebook to clone and reset from master branch when publishing
***** fill up pydocstrings for publishable functions
***** add all dependencies and information on how to install
***** add information on init.sh and how to use
