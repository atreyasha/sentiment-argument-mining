** Developments 

*** Argumentation workflow
 
**** Training pipeline
***** TODO check classification reports and then try class/sample weighting for better class balanced loss
***** TODO adjust learning rates in grid-search to be slightly higher than lowest bound, perhaps add batch/layer normalization back to layers
***** TODO add grid-search json to help with choices defined on disk
***** TODO look at *run.ai* for accumulation optimzers and implement training generators -> can increase batch-size for grid-search
***** TODO work on task 1 and observe how multi-task setting could improve both tasks, use *adjacency matrix* for second task
***** TODO update models in logs to have 0 index for cnn and lstm *and* with/without class weights
***** possible script for continue training if patience not triggered; look up model reconstruction by adding custom objects
***** when converting to graph, mask out N to zero in adjacency matrix

**** Sequence encoding
***** TODO improve multitask data processing pipeline with task specification and complete json corpus with argument structure as matrix
***** TODO improve splits in next runs with more thought put behind into distribution of splits
***** look into argument structure and ensure all arguments are present in same paragraph
***** find shorter sequence candidates in UNSC corpus for testing out model 

**** Domain debiasing
***** TODO remove capital names and references to reduce bias
***** increase sequence length by using accumulation to allow more data to feed into network 
     
**** Code-specifc development
***** TODO find out how to include fixed names into requirements.txt file such as tensorflow, despite no explicit call in script, figure out pip local environment and how to fix this for future development
***** TODO update all readmes and pydocstrings, check unused imports and code health in general
***** add appropriate citations for code, review to make sure this is done correctly
***** add existing folder checks, creation if missing and trailing slash addition

**** Task construction
***** task 1 -> 1: claim, 2: premise, 3: non-argument
***** task 2 (dependent on task 1) -> form argumentation structure with adjacency matrix, multiply input from task 1 by row
     
**** Story for presentation
***** clause extraction did not show reliable results with benepar and hard to process
***** mention using various [SEP] indicators for flipping sentences (need some more backup information for this process)
***** mention memory issues related to bert, therefore trying albert with single gpu -> talk about differences between albert and bert
***** also shorter sequence length due to memory issues, makes for better toy examples

**** Ideas to explore
***** ibm argumentation dataset
***** coreference resolution for tree structures
***** try genereous claims and premises creation and map via negative sampling to actual trees and redundant candidates
